# EmoRemap
<img width="1233" alt="lunwen0914" src="https://github.com/lemon-ustc/EmoRemap_samples/assets/114217953/7057aa11-71e7-4eb6-a27a-855a348a7be0">

# Abstract
Although current Text-To-Speech (TTS) models are able to generate high-quality speech samples, emotion intensity controllable TTS remains a difficult challenge. Most existing TTS models achieve emotion intensity control by extracting intensity information from reference speeches. Unfortunately, limited by the lack of modeling for intra-class emotion intensity and the model's information decoupling capability, the generated speech cannot achieve fine-grained emotion intensity control and suffers from information leakage issues. In this paper, we propose an emotion transfer TTS model, which defines a remapping method to model intra-class relative intensity information, combined with mutual information (MI) to decouple speaker and emotion information, and synthesizes expressive speeches with clearly perceivable intensity. Experiments show that our model achieves fine-grained emotion control while preserving speaker information.

# EmoRemap_demos

Our Demo Page: <https://lemon-ustc.github.io/EmoRemap-demo/>

